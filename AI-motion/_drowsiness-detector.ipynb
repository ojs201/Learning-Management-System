{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac4b0e9",
   "metadata": {},
   "source": [
    "## 얼굴&눈 영역 인식하여 졸음 인식하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb909952",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 133\u001b[0m\n\u001b[1;32m    130\u001b[0m     detectAndDisplay(frame)\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# q 입력시 종료\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    136\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "RIGHT_EYE = list(range(36, 42))\n",
    "LEFT_EYE = list(range(42, 48))\n",
    "EYES = list(range(36, 48))\n",
    "\n",
    "frame_width = 640\n",
    "frame_height = 480\n",
    "\n",
    "title_name = 'Drowsiness_Detection'\n",
    "\n",
    "face_cascade_name = './haarcascade_frontalface_alt.xml'\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "if not face_cascade.load(cv2.samples.findFile(face_cascade_name)):\n",
    "    print('--(!)Error loading face cascade')\n",
    "    exit(0)\n",
    "\n",
    "predictor_file = './shape_predictor_68_face_landmarks.dat'\n",
    "predictor = dlib.shape_predictor(predictor_file)\n",
    "\n",
    "status = 'Awake'\n",
    "number_closed = 0\n",
    "min_EAR = 0.275\n",
    "closed_limit = 15 #-- 눈 감김이 15번 이상일 경우 졸음으로 간주\n",
    "show_frame = None\n",
    "sign = None\n",
    "color = None\n",
    "\n",
    "# EAR: Eye Aspect Ratio 눈의 비율을 이용해 눈 감김 체크\n",
    "def getEAR(points):\n",
    "    A = np.linalg.norm(points[1] - points[5])\n",
    "    B = np.linalg.norm(points[2] - points[4])\n",
    "    C = np.linalg.norm(points[0] - points[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "    \n",
    "def detectAndDisplay(image):\n",
    "    global status\n",
    "    global number_closed\n",
    "    global color\n",
    "    global show_frame\n",
    "    global sign\n",
    "\n",
    "    image = cv2.resize(image, (frame_width, frame_height))\n",
    "    #show_frame = cv2.flip(image, 1)\n",
    "    show_frame = image\n",
    "    frame_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.equalizeHist(frame_gray) \n",
    "    # equalizeHist: 영상의 픽셀값들의 누적분포함수를 이용하여 영상을 개선하는 방법\n",
    "    faces = face_cascade.detectMultiScale(frame_gray)\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        # openCV이미지를 dlib용 사각형으로 변환\n",
    "        rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))\n",
    "        #랜드마크 포인트 지정\n",
    "        points = np.matrix([[p.x, p.y] for p in predictor(image, rect).parts()])\n",
    "        #원하는 포인트(눈)\n",
    "        show_points = points[EYES]\n",
    "        \n",
    "        right_eye_EAR = getEAR(points[RIGHT_EYE])\n",
    "        left_eye_EAR = getEAR(points[LEFT_EYE])\n",
    "        mean_eye_EAR = (right_eye_EAR + left_eye_EAR) / 2 \n",
    "\n",
    "        right_eye_center = np.mean(points[RIGHT_EYE], axis = 0).astype(\"int\")\n",
    "        left_eye_center = np.mean(points[LEFT_EYE], axis = 0).astype(\"int\")\n",
    "\n",
    "        cv2.putText(image, \"{:.2f}\".format(right_eye_EAR), (right_eye_center[0,0], right_eye_center[0,1] + 20),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        cv2.putText(image, \"{:.2f}\".format(left_eye_EAR), (left_eye_center[0,0], left_eye_center[0,1] + 20),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "        for (i, point) in enumerate(show_points):\n",
    "            x = point[0,0]\n",
    "            y = point[0,1]\n",
    "            cv2.circle(image, (x, y), 1, (0, 255, 255), -1)\n",
    "            \n",
    "        if mean_eye_EAR > min_EAR: # 눈 뜸\n",
    "            color = (0, 255, 0)\n",
    "            status = 'Awake'\n",
    "            #number_closed = number_closed - 1\n",
    "            number_closed = 0\n",
    "            if( number_closed<0 ):\n",
    "                number_closed = 0\n",
    "        else: # 눈 감음\n",
    "            color = (0, 0, 255)\n",
    "            #status = 'sleep'\n",
    "            number_closed = number_closed + 1\n",
    "            \n",
    "        if number_closed > closed_limit:\n",
    "            color = (0, 0, 255)\n",
    "            status = 'sleep'\n",
    "                     \n",
    "        sign = 'sleep count : ' + str(number_closed) + ' / ' + str(closed_limit)\n",
    "\n",
    "\n",
    "    cv2.putText(show_frame, status , (frame_width//2 - 100,frame_height-430), cv2.FONT_HERSHEY_DUPLEX, 2, color, 2)\n",
    "    cv2.putText(show_frame, sign , (10,frame_height-20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    cv2.imshow(title_name, show_frame)\n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "time.sleep(2.0)\n",
    "if not cap.isOpened:\n",
    "    print('Could not open video')\n",
    "    exit(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if frame is None:\n",
    "        print('Could not read frame')\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "    detectAndDisplay(frame)\n",
    "    \n",
    "    # q 입력시 종료\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdedd82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86917fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
